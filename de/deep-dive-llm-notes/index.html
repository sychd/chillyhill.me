<!doctype html>
<html lang="de" dir="ltr">
  <head>
    <script type="module">
      const theme = localStorage.getItem('color-scheme');
      document.documentElement.classList = theme;
    </script>
    <meta charset="utf-8" />
    <link rel="icon" href="../../favicon/favicon.ico" />
    <title>Chillyhill - Sych's blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="description" content="Chillyhill" />
    <meta
      name="keywords"
      content="blog, technology, coding, programming, science fiction, philosophy, well-being"
    />
    <meta name="author" content="Denys Sych" />
    <meta name="robots" content="index, follow" />
    <meta name="google-site-verification" content="elucFECRq9znF7rKTQzAZqWBemBraHb9b4W11m6SBLU" />
    
		<link href="../../_app/immutable/assets/0.DQSU0Hx9.css" rel="stylesheet">
		<link rel="modulepreload" href="../../_app/immutable/entry/start.C1nE7wWL.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/entry.BsZ637mg.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/runtime.DVXmTssb.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/paths.DLbR3Kp-.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/control.CYgJF_JY.js">
		<link rel="modulepreload" href="../../_app/immutable/entry/app.B-w26vHK.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/preload-helper.C1FmrZbK.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/i18n.CgqlnT4A.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/disclose-version.CFYEnLtd.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/legacy.Cl-uuIUX.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/render.C7Jwyn5P.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/if.CBuUu9t6.js">
		<link rel="modulepreload" href="../../_app/immutable/nodes/0.9v5sRmz4.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/snippet.B1KECos-.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/lifecycle.DeXqQzN3.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/index.C_phpqAG.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/each.GTZOBD8j.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/attributes.DIOS-3Y0.js">
		<link rel="modulepreload" href="../../_app/immutable/nodes/3.DSLmUZj4.js">
		<link rel="modulepreload" href="../../_app/immutable/chunks/utils.D2VCOvFc.js"><!--[--><!--[--><script defer="" src="https://cloud.umami.is/script.js" data-website-id="6f688109-6024-4733-9aad-826681849c91"></script><!----><!--]--><!--]--><!--[--><!--[--><!--[--><!--[--><link rel="alternate" hreflang="en" href="http://sveltekit-prerender/deep-dive-llm-notes/"><link rel="alternate" hreflang="de" href="http://sveltekit-prerender/de/deep-dive-llm-notes/"><link rel="alternate" hreflang="uk" href="http://sveltekit-prerender/uk/deep-dive-llm-notes/"><link rel="alternate" hreflang="ru" href="http://sveltekit-prerender/ru/deep-dive-llm-notes/"><!--]--><!--]--><!--]--><!--]--><!--[--><meta property="og:type" content="article"> <meta property="og:title" content="Deep dive into LLMs with Andrej Karphaty"><!--]--><title>Deep dive into LLMs with Andrej Karphaty</title>
  </head>
  <body data-sveltekit-preload-data="hover">
    <div style="display: contents"><!--[--><!--[--><!----><!----><!----><div class="flex min-h-screen flex-col bg-gray-50 dark:bg-gray-800"><header class="relative z-10 flex h-14 items-center justify-between bg-gradient-to-b from-primary/10 to-transparent py-2"><section class="container flex flex-shrink-0 items-center justify-between gap-4 text-nowrap"><a href="/de/" class="flex items-center font-logo text-3xl text-cyan-900 dark:text-secondary">Chillyhill ‚õ∞Ô∏é</a> <div class="flex flex-nowrap items-center gap-4"><!--[!--><!--]--> <button aria-label="Toggle theme" class="invisible"><!--[!--><div>üåô</div><!--]--></button><!----></div></section></header><!----> <main class="flex flex-grow flex-col"><!----><article class="flex flex-grow flex-col overflow-hidden bg-gray-50 px-4 py-8 text-gray-300 dark:bg-gray-800"><div class="container flex flex-grow flex-col"><hgroup class="prose mb-6 flex max-w-full flex-col items-center justify-between dark:prose-invert"><h1 class="mb-0 font-bold text-primary dark:text-secondary">Deep dive into LLMs with Andrej Karphaty</h1> <div class="flex items-center italic text-gray-600 dark:text-gray-300"><p class="text-sm font-medium">Published on Feb 13, 2025</p></div></hgroup> <div class="prose prose-lg max-w-full flex-grow dark:prose-invert prose-headings:text-gray-800 dark:prose-headings:text-gray-200"><p>Here are some notes taken while wotching the video on LLMs created by Andrej Karphathy. Thank you, Andrej!</p> <ul><li><p>The video itself: <a href="https://www.youtube.com/watch?v=7xTGNNLPyMI&amp;ab_channel=AndrejKarpathy" rel="nofollow">https://www.youtube.com/watch?v=7xTGNNLPyMI&amp;ab_channel=AndrejKarpathy</a></p></li> <li><p>How data is being tokenized: <a href="https://tiktokenizer.vercel.app/" rel="nofollow">https://tiktokenizer.vercel.app/</a></p></li> <li><p>Visualisation of CNNs: <a href="https://bbycroft.net/llm" rel="nofollow">https://bbycroft.net/llm</a></p></li></ul> <h2>Initial training</h2> <p>It involves data crawling, parsing, clearing out. Then tokenizing and feeding into CNN. The weights are adjusted and as a result we have BASE or completion models. This process is extremely computational intensive.</p> <h2>*-instruct models</h2> <p>Means that they are not just BASE models but also were taught by huge set of ‚Äúfew-shot‚Äù conversations created by human experts and labellers.</p> <h2>Few-shot learning</h2> <p>Ball: Ball, Dog: Hund, Cat: ‚Ä¶</p> <p>Here LLM adds ‚ÄúKatze‚Äù based on the few shots.</p> <h2>‚ÄúVague recollection‚Äù vs. ‚ÄúWorking memory‚Äù</h2> <p>Knowledge in the parameters == Vague recollection (e.g. of something you read 1 month ago)
Knowledge in the tokens of the context window == Working memory.</p> <p>Working memory is usually done by pre-feeding (copy&amp;paste) data in the general prompt or by RAG solutions.</p> <h2>LLM‚Äôs Self</h2> <p>It is input-output pure function, no self! Each times it starts, runs its statistic/stochastic stuff and then shuts off.</p> <p>During the fine-tuning it gets this ‚Äúself‚Äù during fine-tuning or based on the similar data in the internet. So it can hallucinate easily.</p> <p>Still, you can program this out.</p> <h2>It needs tokens to ‚Äúthink‚Äù</h2> <p><img src="/_app/immutable/assets/image.UPuWNdFG.png" alt="image.png"></p> <p>Left is significantly worse! It gives immediately the answer. That is totally bad for training. It reads and generates tokens from left to right.</p> <p>On the right, we show ongoing process, we create step-by-step calculations.</p> <p>So it builds its own context window, building tokens one by one, and helping itself to come to the answer.</p> <h3>Hint by Andrej ‚Äî ask to lean on tools</h3> <p>For such kind of questions it is better to ask ‚Äúuse code‚Äù, because it would do a solution more reliable. LLM uses a tool, it is not relying on its mental arithmetic.</p> <p>You can also ask ‚Äúuse code interpreter‚Äù or ‚Äúuse web search‚Äù.</p> <p><strong>Lean on tools whenever it is possible.</strong></p> <p>Model is not good at thinking. Model is good at copy&amp;pasting.</p> <h3>Models do not think</h3> <p>Models can‚Äôt count.</p> <p>Models do not see letters, characters, they are not good at spelling now. They usually have tokens that may include many char-s within single token.</p> <h3>SFT model</h3> <p>Supervised fine-tuned model. It is the result of this post-training step. It kinda mimics the expert‚Äôs solutions, statistically.</p> <h2>Reinforcement learning</h2> <p>Next step in post-learning process, based on SFT model. It goes beyond mimics and goes to reasoning.</p> <p><img src="/_app/immutable/assets/image-1.BaZAEMX-.png" alt="image.png"></p> <p>So it is kinda we get ‚Äúpre-training‚Äù by reading the theory, then we have worked problems resolved by a professional (author of the book) to learn how to solve the problems.</p> <p>Then, we can have a task to resolve and the final answer to compare with ours result, but solution we build on our own. And here we go with reinforcement.</p> <p>Our knowledge is not LLMs knowledge. But we (human experts / labellers) give a hint of our cognition by providing samples.</p> <p>We need to encourage solutions that lead to correct answers.</p> <p>We decide which is the best and then feed it to the model.</p> <p><img src="/_app/immutable/assets/image-2.D06sQsGN.png" alt="image.png"></p> <h3>RL (‚Äùthinking‚Äù) Model</h3> <p>It is reinforcement learning model.</p> <p>It is about refrain, backtrack, reevaluate ‚Äî it is so-called chain-of-thought. The model discovers the way to think.</p> <p>Check the result of different perspectives. It is not hardcoded or shown by example. We just give the answer and it tries to find the most effective solution.</p> <p>Another name is ‚Äúreasoning‚Äù model. DeepSeek was first who has represented this into a wide public.</p> <h2><a href="http://together.ai" rel="nofollow">together.ai</a></h2> <p>The resource you can use to use deployed models not by main players. E.g. you can talk to DeepSeek R1 without interacting with their actual hosts (as a company). You can also do it in Azure, still it is not as user-friendly as <a href="https://together.ai" rel="nofollow">https://together.ai</a></p> <h3>Reinforcement learning in un-verifiable domains ‚áí RLHF (Reinforcement learning with Human Feedback)</h3> <p>E.g. jokes, humour, poems. There is a problem to score well so ‚ÄúLLM Judge‚Äù is not so helpful, so we use human feedback.</p> <p>Neural Network (reward model, complete separate neural network) can build based on that simulation of human preferences.</p> <p>So, we‚Äôre slightly nudging weights iteratively until it aligns well with human scores.</p> <h3>Discriminator ‚Äî generator gap</h3> <p>It is easier for human to discriminate than to generate. So, human labeller would rather pick one of the best responses (poem .e.g.) instead of writing his own one.</p> <h3>Downside</h3> <p>It can still go wrong as RN can find a way to ‚Äúoutsmart‚Äù the scoring. So it can find a way to trick the scoring model and bring shitty results.</p> <p><img src="/_app/immutable/assets/image-3.C5SN--D8.png" alt="image.png"></p> <h2>Something is good, something is not</h2> <p>At some tasks LLMs are great, at some tasks they are not so good. Keep in mind, they are tools.</p><!----></div></div></article><!----><!----></main> <footer class="relative h-16 bg-[url('/images/background-banner.svg')] bg-cover bg-center"><div class="absolute h-6 w-full bg-gradient-to-t from-transparent to-gray-50 dark:to-gray-800"></div> <section class="container"><div class="flex pt-8 text-xs text-cyan-900 dark:text-secondary">Denys Sych ¬© 2025</div></section></footer></div><!----><!----><!----><!--]--> <!--[!--><!--]--><!--]-->
			
			<script>
				{
					__sveltekit_1oapogj = {
						base: new URL("../..", location).pathname.slice(0, -1)
					};

					const element = document.currentScript.parentElement;

					const data = [null,null];

					Promise.all([
						import("../../_app/immutable/entry/start.C1nE7wWL.js"),
						import("../../_app/immutable/entry/app.B-w26vHK.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 3],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
  </body>
</html>
